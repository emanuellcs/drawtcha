{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawtcha: Unified CNN and RNN Model Training\n",
    "\n",
    "This notebook combines the training of the two AI models for the Drawtcha project into a single file. It will:\n",
    "1.  Train the **CNN Model** on image (bitmap) data.\n",
    "2.  Save the model as `cnn_model_tf.h5`.\n",
    "3.  Clear the system memory.\n",
    "4.  Train the **RNN Model** on sequential stroke data.\n",
    "5.  Save the model as `rnn_model_tf.h5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial Setup\n",
    "Imports all necessary libraries for both models and defines the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "CATEGORIES = [\"cat\", \"bicycle\", \"tree\", \"fish\", \"star\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: CNN Model Training (Image Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. CNN Data Preparation (Bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL_BITMAP = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/\"\n",
    "RAW_DATA_DIR_CNN = \"data/raw_bitmap\"\n",
    "\n",
    "if not os.path.exists(RAW_DATA_DIR_CNN):\n",
    "    os.makedirs(RAW_DATA_DIR_CNN)\n",
    "\n",
    "print(\"--- Downloading data for the CNN ---\")\n",
    "for category in CATEGORIES:\n",
    "    url = f\"{BASE_URL_BITMAP}{category}.npy\"\n",
    "    filepath = os.path.join(RAW_DATA_DIR_CNN, f\"{category}.npy\")\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {category}.npy...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    else:\n",
    "        print(f\"{category}.npy already exists.\")\n",
    "\n",
    "all_images = []\n",
    "all_labels_cnn = []\n",
    "for i, category in enumerate(CATEGORIES):\n",
    "    filepath = os.path.join(RAW_DATA_DIR_CNN, f\"{category}.npy\")\n",
    "    data = np.load(filepath)\n",
    "    images = data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "    all_images.append(images)\n",
    "    labels = np.full(images.shape[0], i)\n",
    "    all_labels_cnn.append(labels)\n",
    "\n",
    "final_images = np.concatenate(all_images, axis=0)\n",
    "final_labels_cnn = np.concatenate(all_labels_cnn, axis=0)\n",
    "print(f\"\\nImage processing complete. Shape: {final_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. CNN Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(CATEGORIES)\n",
    "\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n",
    "\n",
    "x_train_cnn, x_val_cnn, y_train_cnn, y_val_cnn = train_test_split(\n",
    "    final_images, final_labels_cnn, test_size=0.2, random_state=42, stratify=final_labels_cnn\n",
    ")\n",
    "\n",
    "BATCH_SIZE_CNN = 128\n",
    "train_dataset_cnn = tf.data.Dataset.from_tensor_slices((x_train_cnn, y_train_cnn)).shuffle(len(x_train_cnn)).batch(BATCH_SIZE_CNN).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset_cnn = tf.data.Dataset.from_tensor_slices((x_val_cnn, y_val_cnn)).batch(BATCH_SIZE_CNN).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\n--- Starting CNN training ---\")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "cnn_history = cnn_model.fit(train_dataset_cnn, epochs=10, validation_data=val_dataset_cnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Save CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model_tf.h5')\n",
    "print(\"\\nCNN model successfully saved as cnn_model_tf.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Memory Cleanup\n",
    "Before training the next model, we clear the memory to prevent resource exhaustion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_images, final_labels_cnn, x_train_cnn, x_val_cnn, y_train_cnn, y_val_cnn, cnn_model, train_dataset_cnn, val_dataset_cnn\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "print(\"Memory cleared. Ready for the RNN model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: RNN Model Training (Stroke Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. RNN Data Preparation (Strokes)\n",
    "\n",
    "**Memory Optimization:** Limit the number of drawings loaded per category to avoid exceeding RAM limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL_STROKE = \"https://storage.googleapis.com/quickdraw_dataset/full/simplified/\"\n",
    "RAW_DATA_DIR_RNN = \"data/raw_strokes\"\n",
    "MAX_SEQ_LENGTH = 200\n",
    "MAX_DRAWINGS_PER_CATEGORY = 50000  # OPTIMIZATION: Limit drawings to prevent RAM overflow\n",
    "\n",
    "if not os.path.exists(RAW_DATA_DIR_RNN):\n",
    "    os.makedirs(RAW_DATA_DIR_RNN)\n",
    "\n",
    "print(\"--- Downloading data for the RNN ---\")\n",
    "for category in CATEGORIES:\n",
    "    url = f\"{BASE_URL_STROKE}{category}.ndjson\"\n",
    "    filepath = os.path.join(RAW_DATA_DIR_RNN, f\"{category}.ndjson\")\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {category}.ndjson...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    else:\n",
    "        print(f\"{category}.ndjson already exists.\")\n",
    "\n",
    "def strokes_to_sequence(strokes):\n",
    "    \"\"\"Converts raw stroke data into a sequence of [x, y, pen_state] points.\"\"\"\n",
    "    sequence = []\n",
    "    for stroke in strokes:\n",
    "        for i in range(len(stroke[0])):\n",
    "            pen_state = 1 if i == 0 else 0\n",
    "            sequence.append([stroke[0][i], stroke[1][i], pen_state])\n",
    "    return np.array(sequence[:MAX_SEQ_LENGTH], dtype=np.float32)\n",
    "\n",
    "all_sequences = []\n",
    "all_labels_rnn = []\n",
    "for i, category in enumerate(CATEGORIES):\n",
    "    filepath = os.path.join(RAW_DATA_DIR_RNN, f\"{category}.ndjson\")\n",
    "    print(f\"Processing {category}...\")\n",
    "    with open(filepath, 'r') as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if count >= MAX_DRAWINGS_PER_CATEGORY:\n",
    "                break\n",
    "            \n",
    "            drawing = json.loads(line)\n",
    "            seq = strokes_to_sequence(drawing['drawing'])\n",
    "            padded_seq = np.zeros((MAX_SEQ_LENGTH, 3), dtype=np.float32)\n",
    "            padded_seq[:len(seq)] = seq\n",
    "            all_sequences.append(padded_seq)\n",
    "            all_labels_rnn.append(i)\n",
    "\n",
    "final_sequences = np.stack(all_sequences, axis=0)\n",
    "final_labels_rnn = np.array(all_labels_rnn, dtype=np.uint8)\n",
    "print(f\"\\nStroke processing complete. Shape: {final_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. RNN Model Definition and Training\n",
    "\n",
    "**Memory Optimization:** The LSTM layers are reduced to 128 units and the batch size is set to 64 to lower memory consumption during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        # OPTIMIZATION: Reduced LSTM units from 256 to 128. If you have more resources on your machine, you can return to 256.\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.LSTM(128),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = (MAX_SEQ_LENGTH, 3)\n",
    "num_classes = len(CATEGORIES)\n",
    "rnn_model = create_rnn_model(input_shape, num_classes)\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()\n",
    "\n",
    "x_train_rnn, x_val_rnn, y_train_rnn, y_val_rnn = train_test_split(\n",
    "    final_sequences, final_labels_rnn, test_size=0.2, random_state=42, stratify=final_labels_rnn\n",
    ")\n",
    "\n",
    "# OPTIMIZATION: Use a smaller batch size for RNN training. If you have more resources on your machine, you can change it to a higher value.\n",
    "BATCH_SIZE_RNN = 64\n",
    "train_dataset_rnn = tf.data.Dataset.from_tensor_slices((x_train_rnn, y_train_rnn)).shuffle(len(x_train_rnn)).batch(BATCH_SIZE_RNN).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset_rnn = tf.data.Dataset.from_tensor_slices((x_val_rnn, y_val_rnn)).batch(BATCH_SIZE_RNN).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\n--- Starting RNN training ---\")\n",
    "early_stopping_rnn = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "rnn_history = rnn_model.fit(train_dataset_rnn, epochs=15, validation_data=val_dataset_rnn, callbacks=[early_stopping_rnn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Save RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.save('rnn_model_tf.h5')\n",
    "print(\"\\nRNN model successfully saved as rnn_model_tf.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "Training complete! The following files have been generated and are ready to be used in the FastAPI backend:\n",
    "- `cnn_model_tf.h5`\n",
    "- `rnn_model_tf.h5`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
